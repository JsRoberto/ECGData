---
title: "Algoritmo de Pan & Tompkins para detecção de complexos QRS"
author: "José Roberto Sobrinho Lima e Luana Gonçalves"
date: "8 de outubro de 2016"
output: pdf_document
---
***
#Relatório  
***

##1. Introdução e Metodologia  

Doenças cardíacas estão entre as principais causas de mortalidade no mundo. Por esse motivo, há constante preocupação em melhorar o poder diagnóstico de equipamentos que monitoram a condição cardíaca. Uma grande variedade de dispositivos analisa a atividade cardíaca, produzindo informações que facilmente podem ser digitalizadas e processadas por computador. A medida que o poder computacional dessas máquinas cresce, os diagnósticos resultantes apresentam acurácia e precisão maiores.  

Em processamento de eletrocardiogramas (ECG), uma base importante para fundamentar posteriores análises dos dados é a acurácia na detecção de batimentos cardíacos. Nesse sentido, como a energia dos batimentos está localizada nos complexos QRS[nota 1], acurácia na detecção desses complexos é essencial para a análise de ECG.  

Devido à variação ao longo do tempo e aos diferentes tipos de ruído que podem contaminar o sinal ECG, a detecção do complexo QRS é uma tarefa difícil.  

Os algoritmos de detecção dos complexos QRS apresentam duas fases distintas: (1) o estágio de pré-processamento, que consiste em aplicar técnicas de filtragem linear e não linear ou “_smoothing_” – o objetivo é atenuar as ondas P e T, bem como os ruídos contaminantes; e (2) o estágio de decisão, que apresenta como tarefas mais importantes a determinação de “_thresholds_” para classificação e, em alguns casos, a discriminação de ondas T e a redução de falsos positivos.  

O algoritmo de detecção do complexo QRS a ser estudado e aplicado será o algoritmo de _Pan-Thompkins_, cujas etapas de processamento serão abordadas mais adiante. A discussão inclui a análise em pormenor do um código fonte desenvolvido neste trabalho e que utilizou parâmetros previamente estabelecidos em literatura sobre o tema [ref. ÁLVAREZ].  

O algoritmo de _Pan-Thopmpkins_ será aplicado sobre uma base de dados pública, obtida gratuitamente do bando de dados do _Physionet_[nota 2]. Mais especificamente, os dados que utilizaremos foram coletados e armazenados pelo _MIT_ e pelo _Boston’s Beth Israel Hospital_ (_MIT-BIH Arrhythmia Database_) segundo metodologia amplamente submetida a discussões e críticas – **ainda hoje carregando bastante credibilidade e relevância acadêmica**. Além, disso essa base de dados é focada em sinais com as mais diversas morfologias de complexos QRS[nota 3],  o que permite investigar a performance dos algoritmos de detecção desses complexos – daí, portanto, seu extensivo uso para validação desses algoritmos.  

O _MIT-BIH Arrhythmia Database_ contém 48 horas e meia de gravações coletadas utilizando-se dois canais de entrada. Todavia, o código fonte que desenvolvemos processará somente um desses canais: se um desses canais registrar sinais de alta qualidade, normalmente isso implica que o segundo canal registrará sinais de baixa amplitude e de baixa relação sinal-ruído[nota 4] (obs.: talvez mais alguma informação sobre o MIT-BIH).  

Os softwares utilizados serão:   
(1) _MatLab_, da _Mathworks_ – utilizar-se-á o WFDB Toolbox[nota 5], 
(2) _RStudio_, linguagem de programação R – ...para realizar o processamento dos sinais de ECG do MIT-BIH é a linguagem de programação R. Seus principais atrativos são seus ferramentais voltados para computação estatística e modelagem gráfica. Além disso, o software é _open source_ e apresenta estrutura multiplataforma.  

O algoritmo de Pan-Thompkins é baseado em filtros digitais, possuindo filtros passa-baixa e passa-alta em cascata e com frequências de cortes diferentes resultando em um sinal filtrado passa-banda.

***
##2. O código fonte  

O código fonte desenvolvido neste trabalho pode ser dividido em três momentos.  

###2.1 Fase de estabelecimento  

Esta etapa consiste em (1) estabelecer as bibliotecas a serem utilizadas dentro do código, entre as quais temos os pacotes gráficos _ggplot2_, _lattice_ e _gridExtra_, além do pacote _signal_, com funções de filtros digitais diretamente importadas do MatLab e Octave[ref. signal CRAN]; (2) baixar e salvar no diretório de trabalho os dois arquivos necessários ao processamento – *mtidb_signals.csv* e *fs.csv*; e (3) criar a principal função de plotagem gráfica _dataECGplot()_, que mostrará os resultados das principais etapas do processamento dos sinais.  

```{r setoptions}
knitr::opts_chunk$set(autodep = TRUE, cache = TRUE, warning = FALSE, results = "hide")
```

```{r}
#Localizar a biblioteca e definir os pacotes não padrões a serem utilizados.
.libPaths("C:/Users/JoséRoberto/AppData/Roaming/SPB_16.6/R/win-library/3.2")
library(signal)
library(ggplot2)
library(lattice)
library(gridExtra)

#Baixar os arquivos "mitdb_ecgSignals.csv" e "fs.csv" - caso ainda não tenham sido.
Url <- c("https://raw.githubusercontent.com/JsRoberto/ECGData/master/mitdb_ecgSignals.csv"
         ,"https://raw.githubusercontent.com/JsRoberto/ECGData/master/fs.csv")
Local <- c("mitdb_ecgSignals.csv","fs.csv")

download <- function(Local, Url) {
      if (!file.exists(Local)) {
            download.file(Url, Local)
      }
}

mapply(download, Local, Url)

#Salvar em formatos adequados as variáveis que representam os sinais.
Ecg.signals <- read.csv("mitdb_ecgSignals.csv", stringsAsFactors = FALSE)
Ecg.signals <- Ecg.signals[-((6*21601+1):dim(Ecg.signals)[1]),]
Ecg.signalSplit <- split(Ecg.signals, Ecg.signals$signal_case)
fs <- read.csv("fs.csv")
fs <- as.numeric(fs)
```
  
```{r results = "markup"}
#São obtidos a média "Mean1" e o desvio padrão "Std1" dos sinais não filtrados.
Mean1 <- sapply(Ecg.signalSplit, function(x) mean(x$signal_mag, na.rm = TRUE))
Std1 <- sapply(Ecg.signalSplit, function(x) sd(x$signal_mag, na.rm = TRUE))
Mean1
Std1
```
  
```{r}
#A função "filter_ecgSignals()" pretende aplicar sobre a lista de sinais "data_ecg" o 
#---filtro definido por uma função de transferência com numerador "H_Num" e denominador
#---"H_Den". Além disso, o sinal filtrado resultante "x_norm" está normalizado.
filter_ecgSignals <- function(data_ecgSplit, H_Num, H_Den) {
      x <- lapply(data_ecgSplit, function(x) x$signal_mag - mean(x$signal_mag))
      x <- sapply(x, filter, filt = H_Num, a = H_Den)
      x <- as.data.frame(x)
      x_norm <- sapply(x, function(x) {
            x <- x/max(abs(x))
      })
      x_norm <<- as.data.frame(x_norm)
}

filter_ecgSignals(Ecg.signalSplit, 1, 1)

#A função "update.filtSignal()" pretende atualizar a lista de sinais "Ecg.signalSplit"
#---pela lista de valores filtrados e normalizados "x_norm".
update.filtSignal <- function(Ecg.signalSplit, x_norm) {
      for (i in 1:length(Ecg.signalSplit)) {
            Ecg.signalSplit[[i]]$signal_mag <<- x_norm[[i]]
      }
}

update.filtSignal(Ecg.signalSplit, x_norm)
```
  
```{r results = "markup"}
#São obtidos a média "Mean2" e o desvio padrão "Std2" dos sinais normalizados.
Mean2 <- sapply(Ecg.signalSplit, function(x) mean(x$signal_mag, na.rm = TRUE))
Std2 <- sapply(Ecg.signalSplit, function(x) sd(x$signal_mag, na.rm = TRUE))
Mean2
Std2
```
  
```{r graph1}
#A função "dataECGplot()" é a principal função de plotagem do código, responsável por 
#---mostrar a evolução do sinal em cada etapa de processamento.
#---Seus argumentos são:
#---(1) "Ecg.signalSplit" - define a lista de sinais a serem plotados;
#---(2) "interval_seg" - define o intervalo de tempo em que o plote está delimitado;
#---(3) "Fs" - define a frequência de amostragem dos sinais.
dataECGplot <- function(Ecg.signalSplit, interval_seg = 0:60, Fs = fs) {
      Ecg.signalsAUX <- data.frame()
      signal_mag <- vector()
      interval <- 1+((Fs*min(interval_seg)):(Fs*max(interval_seg)))
      for (i in 1:length(Ecg.signalSplit)) {
            signal_mag <- c(signal_mag,
                            Ecg.signalSplit[[i]]$signal_mag[interval])
            Ecg.signalSplit[[i]] <- Ecg.signalSplit[[i]][interval,]
            Ecg.signalsAUX <- rbind(Ecg.signalsAUX,Ecg.signalSplit[[i]])
      }
      Ecg.signalsAUX$signal_mag <- signal_mag
      
      #panel.smoother <- function(x, y) {
      #      panel.grid(h=-1, v=-1)
      #      panel.xyplot(x, y, type = "l", lwd = 1)
      #      panel.abline(h=mean(y), lwd=1, lty=2, col="navy")
      #}
      
      #xyplot(signal_mag ~ t | signal_case, data = Ecg.signalsAUX,
      #       layout=c(3,2),
      #       panel=panel.smoother,
      #       main="Ecg Signals", xlab="time (s)",ylab="Volts")
      
      p1 <- ggplot(Ecg.signalsAUX, aes(x = t, y = signal_mag, group = signal_case)) + 
                  geom_line(color = "blue3") + 
                  facet_wrap( ~ signal_case, nrow = 3) + 
                  labs(title = "Sinais ECG", x = "tempo (s)", y = "magnitude (Volts)")
      
      if (is.null(Ecg.signalsAUX$signal_Rpeaks)) {
            p1
      } else {
            p1 + geom_point(mapping = aes(y = signal_Rpeaks), color = "darkolivegreen3")
      }
}

dataECGplot(Ecg.signalSplit, 25:35)
```
  
###2.2 Algoritmo de _Pan & Thompkins_  

O método que Pan & Tompkins desenvolveram para realizar a detecção dos complexos QRS de sinais de ECG é capaz de realizar a tarefa em tempo. Para tanto, o algoritmo é baseado na inclinação, amplitude e tamanho do sinal - não se limita, pois, somente à inclinação da onda R do sinal.  
Esse algoritmo é divido em dois estágios, pré-processamento e decisão.  
O estágio de pré-processamento consiste em preparar os sinais para a posterior detecção, eliminando os ruidos dos sinais mediante filtros e realçando a inclinação QRS para tornar mais eficiente sua detecção.  
O estágio de decisão consiste em (1) detectar os picos dos sinais, (2) obter e atualizar constantee automaticamente parâmetros que classifiquem esses picos detectados, ou como oriundos de ruidos, ou como próprios do sinal. As informações obtidas durante essa etapa são utilizadas principalmente para eliminar falsos positivos e reintegrar falsos negativos.

####2.2.1 Fase de pré-processamento  

Nessa fase, o sinal passa por um bloco de filtros para reduzir ruídos e influência das ondas T. Esse bloco de filtros é composto por um passa-baixa e um passa-alta em cascata, com o intuito de construir um passa-banda entre 9-20 Hz com 3 dB de atenuação [ref. RANGAYYAN]. O passa-baixa é usado para remover ruídos de altas frequências e o passa-alta é usado para atenuar as ondas P e T e o "baseline drift". O filtro digital passa-banda aumenta a relação sinal-ruido (SNR).  

```{r graph2, fig.height = 5, fig.width = 5, fig.align = "center"}
#Bloco 1 - Filtro passa-baixa.
N_lp <- c(1,rep(0,5),-2,rep(0,5),1)
D_lp <- 32*c(1,-2,1)

H_lpz <- freqz(N_lp, D_lp, Fs = fs) #Fs = 360 Hz admite Fc = 20 Hz.

filter_ecgSignals(Ecg.signalSplit, N_lp, D_lp)

update.filtSignal(Ecg.signalSplit, x_norm)

#A função "fz_plot()" pretende gerar gráficos das respostas frequenciais dos filtros: 
#---magnitude (dB e linear) e fase em função da frequência normalizada.
#---Seus argumentos são: 
#---(1) "filter_freqz" - define o filtro propriamente dito, mediante a classe "freqz";
#---(2) "filter_type" - define se o filtro é passa-baixa "lp" ou passa-alta "hp";
#---(3) "Fs" - define a frequência de amostragem do filtro.
fz_plot <- function(filter_freqz, filter_type, Fs = fs) {
      df <- data.frame(w = rep(0,length(filter_freqz$f)),
                       mag = rep(0,length(filter_freqz$h)),
                       mag_dB = rep(0,length(filter_freqz$h)),
                       phase_degrees = rep(0,length(filter_freqz$h)))
      df$w <- filter_freqz$f/(Fs/2)
      df$mag <- abs(filter_freqz$h)
      df$mag_dB <- 20*log10(abs(filter_freqz$h))
      df$phase_degrees <- (180/pi)*Arg(filter_freqz$h)
      
      vec_aux <- df$mag_dB
      vec_aux <- vec_aux[-1]
      vec_aux <- vec_aux + 3
      vec_aux <- vec_aux^2
      wc_sample <- numeric()
      for (i in 1:(dim(df)[1]/2)) {
            if (df$mag_dB[-1][i] == df$mag_dB[-1][vec_aux == min(vec_aux, na.rm = TRUE)]){
                  wc_sample <- i + 1
            }
      }
      
      interval <- wc_sample:512 #default case: low pass filter "lp"
      type <- "baixa"
      if (filter_type == "hp"){
            interval <- 1:wc_sample
            type <- "alta"
      }
      
      p1 <- ggplot(data=df, aes(x=w, y=mag)) +
                  geom_line(color = "blue3", size = 1) +
                  geom_line(data = df[interval,], color = "red", size = 1.3) +
                  labs(x="",y="Magnitude")
      p2 <- ggplot(data=df, aes(x=w, y=mag_dB)) +
                  geom_line(color = "blue3", size = 1) +
                  geom_line(data = df[interval,], color = "red", size = 1.3) +
                  labs(x="",y="Magnitude (dB)")
      p3 <- ggplot(data=df, aes(x=w, y=phase_degrees)) +
                  geom_line(color = "blue3", size = 1) +
                  labs(x="",y="Fase (graus)")
      
      labs_title <- labs(title=paste0("Filtro passa-",type," - Resposta em Frequência"))
      labs_x <- labs(x=expression(paste("Frequência Normalizada (x ",pi," rad/amostra)")))
      
      grid.arrange(p1 + labs_title, p2, p3 + labs_x, nrow=3)
}

fz_plot(H_lpz, "lp")
```
  
```{r graph3, fig.height = 5, fig.width = 5, fig.align = "center"}
#Bloco 2 - Filtro passa-alta.
N_hp <- c(-1,rep(0,15),32,-32,rep(0,14),1)
D_hp <- 32*c(1,-1)

H_hpz <- freqz(N_hp, D_hp, Fs = fs) #Fs = 360 Hz admite Fc = 9 Hz

filter_ecgSignals(Ecg.signalSplit, N_hp, D_hp)

update.filtSignal(Ecg.signalSplit, x_norm)

fz_plot(H_hpz, "hp")
```

Em seguida, um operador derivativo é aplicado sobre o sinal filtrado anteriormente, fornecendo informações complexas sobre as inclinações. A partir daí, eleva-se ao quadrado ponto a ponto, o que intensifica a inclinação do sinal derivado e ajuda a reduzir falsos positivos causados por ondas T maiores que as usuais.  

```{r graph4}
#Bloco 3 - Operador derivativo.
N_do <- c(2,1,0,-1,-2)
D_do <- 8

filter_ecgSignals(Ecg.signalSplit, N_do, D_do)

update.filtSignal(Ecg.signalSplit, x_norm)

dt.signal <- Ecg.signalSplit

dataECGplot(dt.signal, 25:35)

#Bloco 4 - Operador que eleva os valores dos sinais ao quadrado.
x_norm <- lapply(x_norm, function(x) x - mean(x))
x_norm <- sapply(x_norm, function(x) x^2)
x_norm <- as.data.frame(x_norm)

update.filtSignal(Ecg.signalSplit, x_norm)
```  

Finalmente, uma janela de integração móvel é aplicada, o que agrega informações sobre inclinação e largura do sinal. O tamanho da janela de integração é muito importante, uma vez que deve sempre conter o complexo QRS. As dificuldades são que (1) o complexo QRS pode apresentar diferentes extensões e (2) o tamanho da janela não deve excedê-lo, porquanto não deve se misturar a outras formas de onda, como a onda T. A janela utilizada apresenteu os melhores resultados, segundo ÁLVAREZ, com uma janela de 150 ms - isso corresponde a `r 0.15*fs` amostras para os dados utilizados neste trabalho. Além disso, cabe ressaltar que todas as etapas de processamento, seja a etapa dos filtros que constituem o passa-banda, as operações derivativas ou a janela de integração móvel, todas elas causam _delays_ que devem ser considerados quando comparados os sinais resultantes de cada etapa.  

```{r graph5}
#Bloco 5 - Janela de integração móvel
N_if <- rep(1,54)
D_if <- 54

filter_ecgSignals(Ecg.signalSplit, N_if, D_if)

update.filtSignal(Ecg.signalSplit, x_norm)

mwi.signal <- Ecg.signalSplit

dataECGplot(mwi.signal, 25:35)
```

####2.2.2 Fase de decisão  

Uma vez que o sinal é pré-processado, ele está preparado para a detecção dos complexos QRS. Como dito anteriormente, essa fase tem o objetivo de detectar picos e classificá-los. Esse procedimento será aplicado a dois conjuntos de sinais: o primeiro é o conjunto de sinais filtrados pelo bloco derivativo (doravante _dt.signal_) e o segundo é o cojunto de sinais filtrado pela janela de integração (doravante _mwi.signal_).  

O código que realiza a detecção de picos se apresenta abaixo.  

```{r}
#A função "peakDetection()" apresenta como argumentos (a) "updated.dataSplit", uma lista
#---de sinais atualizada pela função "update.filtSignal()", (b) "samples", a quantidade
#---de amostras que terá cada segmento de um sinal, (c) "Fs", a frequência de amostragem
#---dos sinais.
#---O objetivo desta função é obter duas listas: 
#---(1) "peakValues", que armazena os vetores de picos de cada sinal;
#---(2) "peakIndex", que armazena os vetores de índices de cada pico.
peakDetection <- function(updated.dataSplit, samples, Fs = fs) {
      peak.values <- data.frame()
      peak.index <- list()
      k <- 0:(Fs*60/samples)*samples
      for (i in 1:(Fs*60/samples)) {
            if (i == Fs*60/samples) {
                  k[i+1] <- k[i+1] + 1
            }
            peak.intervalAUX <- lapply(updated.dataSplit,
                                       function(x) x$signal_mag[(k[i]+1):k[i+1]])
            peak.valuesAUX <- lapply(peak.intervalAUX,max)
            peak.indexAUX <- mapply(function(peak,intmag) (k[i]:k[1+i])[intmag==peak],
                                    peak.valuesAUX,peak.intervalAUX)
            maximum <- 0
            for (l in 1:length(updated.dataSplit)){
                  if (length(peak.indexAUX[[l]]) > maximum) {
                        maximum <- length(peak.indexAUX[[l]])
                  }
            }
            if (maximum > 1) {
                  for (aux in 1:length(updated.dataSplit)) {
                        peak.valuesAUX[[aux]] <- c(rep(peak.valuesAUX[[aux]],
                                                       length(peak.indexAUX[[aux]])),
                                                   rep(NA, maximum - length(peak.indexAUX
                                                                            [[aux]])))
                        peak.indexAUX[[aux]] <- c(peak.indexAUX[[aux]],
                                                  rep(NA,maximum - length(peak.indexAUX
                                                                          [[aux]])))
                  }
            }
            peak.valuesAUX <- as.data.frame(peak.valuesAUX)
            peak.values <- rbind(peak.values,peak.valuesAUX)
            for (j in 1:length(updated.dataSplit)) {
                  if (length(peak.index) < j) {
                        peak.index[[j]] <- list()
                  }
                  peak.index[[j]][[i]] <- peak.indexAUX[[j]]
            }
      }
      peakValues <<- as.data.frame(peak.values,
                                   row.names = 1:dim(peak.values)[1])
      peakIndex <<- peak.index
}
```

A natureza dos parâmetros de classificação do algoritmo de Pan & Tompkins é iterativa, ou seja, a cada novo pico classificado, os parâmetros são atualizados para classificar os seguintes. Todavia, cabe a dúvida: como classificar os primeiros picos?  

A solução foi obter um parâmetro classificatório inicial e fixo, a fim de determinar os tipos, se de ruido ou de sinal, da menor quantidade de picos necessária para, a partir daí, utilizar o algoritmo do parâmetro de classificação adaptativo.  

Assim, o parâmetro inicial e fixo foi obtido calculando-se 35 % do valor da mediana do vetor de picos do sinal, quando este foi segmentado em intervalos de 3 segundos ou `r 3*fs` amostras. Esse valor se justifica devido ao seguinte raciocínio: a frequência cardíaca minima do ser humano é de 25 batimentos/min, ou seja, um batimento a cada 2,4 segundos; então, a cada 3 segundos, com certeza há pelo menos um pico R em um sinal de ECG.  

A partir daí, um novo vetor de picos foi gerado a partir de segmentação em intervalos de 80 amostras: intervalos menores detectariam muitos picos, enquanto intervalos maiores poderiam não detectar alguns ou muitos deles. Será precisamente este novo vetor que deverá ser classificado, primeiramente usando o parâmetro inicial fixo e posteriormente o parâmetro adaptativo.

```{r}
#Aplicação sobre a lista "dt.signal".
#A primeira aplicação da função "peakDetection()" é usada pra obter os parâmetros 
#---iniciais de classificação "initial.THR".
peakDetection(dt.signal, fs*3, fs)
initial.THR <- 0.35*apply(peakValues, 2, median, na.rm = TRUE)

#A segunda aplicação da função "peakDetection()" é usada pra obter os valores dos picos
#---que serão usados para classificação.
peakDetection(dt.signal, 80, fs)
```

O algoritmo para obtenção dos parâmetros adaptativos consiste nas seguintes variáveis de iteração:  

SPKI = 0.125 × PEAKI + 0.875 × SPKI **(1)**  
NPKI = 0.125 × PEAKI + 0.875 × NPKI **(2)**  
THR1 = NPKI + 0.25 × (SPKI - NPKI) **(3)**  
THR2 = 0.5 × THR1 **(4)**  

Onde PEAKI é o pico corrente, aplicado sobre a função **(1)** se for um pico de sinal ou sobre a função **(2)** se for um pico de ruido; e as variáveis THR1 e THR2 de **(3)** e **(4)**, respectivamente, são os parâmetros de classificação que se adaptam a cada novo pico classificado.

O código abaixo auxilia na obtenção dessas variáveis.  

```{r}
#A função "PKI()" tem o objetivo de gerar os parâmetros de NPKI e SPKI utilizados por Pan 
#---& Tompkins. Se o "vector.peaks" utilizado argumento for "noise.peaks", NPKI é obtido;
#---se for "signal.peaks", então SPKI é obtido. 
PKI <- function(vector.peaks) {
      if (length(vector.peaks)==1) {
            PEAKI <- vector.peaks[1]
      } else {
            PEAKI <- (0.125*vector.peaks[length(vector.peaks)]
                      + 0.875*PKI(vector.peaks[-length(vector.peaks)]))
      }
      PEAKI
}

#A função "THR()" utiliza os parâmetros NPKI e SPKI, obtidos com a função "PKI()", para
#---gerar os parâmetros de classificação dos picos dos sinais.
THR <- function(SPKI, NPKI) {
      THR1 <<- NPKI + 0.25*(SPKI - NPKI)
      THR2 <<- 0.5*THR1
}
```

O parâmetro THR1 é o principal fator de classificação: se o valor do pico corrente for maior que THR1, ele é classificado como pico de sinal; caso contrário, como pico de ruido. Contudo, existem alguns picos de sinal não detectados, ou devido à irregularidade do sinal, ou devido a formas de ondas com mudanças abruptas de amplitude ou frequência. Ou seja, o método inclui algoritmo para eliminar _**falsos negativos**_.  

Algoritmo para detecção e reintegração de _**falsos negativos**_ → se o intervalo entre os dois últimos picos R detectados for maior que 166 % da média das distâncias entre todos os demais pares de picos R adjacentes, então uma nova condição é testada para verificar a existência de picos R não detectados: ser simultaneamente menor que THR1 e maior que THR2.  
Um novo problema surge quando a distância entre picos R é pequena demais: há grande possibilidade de o último pico R detectado ser, de fato, uma forma de onda T anômala. Em outras palavras, trata-se de um _**falso positivo**_.  

Algoritmo para detecção e eliminação de _**falsos positivos**_ → se o último pico R detectado estiver a menos de 200 ms (ou `r 0.2*fs` amostras) do pico R anterior, então ele é, na verdade, uma onda T; se estiver a mais de 360 ms (ou `r 0.36*fs` amostras), então ele é realmente um pico R. O caso mais complexo é se eles estiveres entre 200 ms e 360 ms (ou `r 0.2*fs` e `r 0.36*fs` amostras), uma vez que pode ser tanto uma onda T anômala quanto um batimento ectópico. Neste caso, cabe ressaltar que o algoritmo é originalmente aplicado somente sobre o sinal derivativo _dt.signal_ (mesmo sabendo disso, também os aplicamos sobre o sinal pós-janela de integração _mwi.signal_): se a inclinação do sinal no último pico R detectado for menor que a metade da inclinação do sinal no pico R anterior, então se trata de uma forma de onda T anômala; caso contrário, é um complexo QRS verdadeiro.  

Abaixo temos os códigos que das funções que (1) inicializam as váriaveis a serem utilizadas pela função de classificação dos picos e (2) a própria função de classificação - incluidos os códigos para realizar o processamento de _**falsos positivos**_ e _**falsos negativos**_.  

```{r}
#A função "initializingVariables()" tem o objetivo de inicializar variáveis importantes 
#---para construir as listas que armazenarão vários dados importantes do processamento:
#---(1) "noise.peaks", os vetores dos picos classificados como picos de ruido;
#---(2) "signal.peaks", os vetores dos picos classificados como picos R ou picos de sinal;
#---(3) "index.Rpeak", os vetores dos indices dos picos definidos em "signal.peaks";
#---(4) "RR.originalIntervals", os vetores das distâncias entre os picos definidos em 
#-------"signal.peaks", segundo as localizações originais no sinal;
#---(5) "num.falsePos", os números que indicam a quantidade de falsos positivos;
#---(6) "num.falseNeg", os números que indicam a quantidade de falsos negativos;
#---(7) "index.falsePos", os vetores que indicam os indices de cada falso positivo;
#---(8) "df.UPDATED", os sinais atualizados com parte das informações das listas acima;
#---(9) "index" e "idx", são índices que auxiliam na iteração da função de classificação
#-------"classifying.peaks()" e na função de atualização "df.updated()", respectivamente.
initializingVariables <- function() {
      RR.originalIntervals <<- list()
      index.falsePos <<- list()
      num.falsePos <<- list()
      num.falseNeg <<- list()
      signal.peaks <<- list()
      noise.peaks <<- list()
      index.Rpeak <<- list()
      index <<- 1
      df.UPDATED <<- list()
      idx <<- 1
}

#A função "classifying.peaks()", devido a sua complexidade, terá comentários explicativos
#---sobre seus blocos de funcionamento ao logo do seu código. Contudo, resumidamente, seu
#---objetivo é gerar as listas "noise.peaks", "signal.peaks", "RR.originalIntervals", 
#---"index.Rpeaks", "num.falsePos", "num.falseNeg" e "index.falsePos" inicializadas
#---anteriormente pela função "initializingVariables()".
#---Como argumentos, são utilizados:
#---(1) "originalValues", a lista dos sinais cujos picos serão classificados;
#---(2) "peakValues" e "peaksIndex", as listas geradas pela função "peakDetection()";
#---(3) "initialTHR", a lista com os parâmetros iniciais de classificação de picos;
#---(4) "Fs", frequencia de amostragem dos sinais.
classifying.peaks <- function(originalValues, peakValues, peakIndex, initial.THR, Fs = fs) {
      #A função "lst2vct()" simplesmente transforma uma lista de vetores em um único 
      #---vetor, o que será necessário mais adiante.
      lst2vct <- function(lst) {
            vct <- vector()
            for (k in 1:length(lst)) {
                  vct <- c(vct,lst[[k]])
            }
            vct
      }
      #-----------------------------------------------------------------------------------
      #O bloco abaixo identifica os dois primeiros picos R de "peakValues", de acordo com
      #---as condições iniciais "initial.THR". Há, também, a necessidade de identificar 
      #---os missing values ou NAs de "peakValues".  
      aux <- j <- 0
      auxNAsup <- auxNAinf <- 0
      for (i in 1:length(peakValues)) {
            if (!is.na(peakValues[i])){
                  if (peakValues[i] > initial.THR) {
                        if (aux < 1) {
                              aux <- aux + 1
                              if (aux == 1) {
                                    j <- i
                              }
                        } else break
                  }
            } else {
                  if (j == 0) {
                        auxNAinf <- c(i,auxNAinf)
                  } else {
                        auxNAsup <- c(i,auxNAsup)
                  }
            }
      }
      #O bloco a seguir inicializa os vetores de classificação "noise.peaksAUX" e 
      #---"signal.peaksAUX"; o vetor de índices dos picos R "index.Speaks", referente a 
      #---"peakValues"; o vetor "RR.originalIntervalsAUX", que armazena a distância entre
      #---amostras de "signal.peaksAUX"; os vetores "index.originalALLpeaks" e 
      #---"index.originalSpeaks", que representam os índices, referentes ao sinal
      #---original, de todos os picos e dos picos de sinal, respectivamente.
      #---Além disso, os valores iniciais acima são utilizados para definir os primeiros
      #---parâmetros de classificação - "SPKI", "NPKI", "THR1" e "THR2".
      if (auxNAsup[1] == 0 & auxNAinf[1] == 0) {
            noise.peaksAUX <- peakValues[1:i][-i][-j]
      } else {
            if (auxNAsup[1] != 0 & auxNAinf[1] != 0) {
                  noise.peaksAUX <- peakValues[1:i][-i][-auxNAsup][-j][-auxNAinf]
            } else {
                  if (auxNAsup[1] == 0) {
                        noise.peaksAUX <- peakValues[1:i][-i][-j][-auxNAinf]
                  }
                  if (auxNAinf[1] == 0) {
                        noise.peaksAUX <- peakValues[1:i][-i][-auxNAsup][-j]
                  }
            }
      }
      signal.peaksAUX <- c(peakValues[j],peakValues[i])
      index.Speaks <- c(j,i)
      index.originalALLpeaks <- lst2vct(peakIndex)
      index.originalSpeaks <- index.originalALLpeaks[index.Speaks]
      RR.originalIntervalsAUX <- diff(index.originalSpeaks)
      SPKI <- PKI(signal.peaksAUX)
      NPKI <- PKI(noise.peaksAUX)
      THR(SPKI,NPKI)
      #As variáveis abaixa são auxiliares para varredura do vetor de picos "peakValues" 
      #---("index.RpeakAUX") e para obtenção de informações sobre falsos positivos e
      #---negativos ("indexIn", "num.falsePosAUX" e "num.falseNegAUX).
      indexIn <- 1
      index.RpeakAUX <- i
      num.falsePosAUX <- NULL
      num.falseNegAUX <- NULL
      #-----------------------------------------------------------------------------------
      #O laço "for" abaixo varre todos os valores de picos que ainda serão classificados.
      for (PEAKI in peakValues[(i+1):length(peakValues)]) {
            index.RpeakAUX <- index.RpeakAUX + 1
            if (!is.na(PEAKI)) {
                  if (PEAKI > THR1) {
                        lastIndex.originalSpeak <- (index.originalSpeaks
                                                    [length(index.originalSpeaks)])
                        lastRR.originalInterval <- (index.originalALLpeaks
                                                    [[index.RpeakAUX]]
                                                    - lastIndex.originalSpeak)
                        #As condições abaixo servem para indicar falsos positivos, ou 
                        #---seja, se um pico detectado como R é, na verdade, um pico T.
                        if (lastRR.originalInterval < 0.36*Fs) {
                              if (lastRR.originalInterval > 0.2*Fs) {
                                    lastIndex <- index.originalALLpeaks[[index.RpeakAUX]]
                                    beforeIndex <- lastIndex.originalSpeak
                                    if (lastIndex < dim(originalValues)[1]){
                                          lastSlope <- (originalValues$signal_mag
                                                        [lastIndex+1] 
                                                        - originalValues$signal_mag
                                                        [lastIndex-1]) * Fs/2
                                    } else {
                                          lastSlope <- (originalValues$signal_mag
                                                        [lastIndex] 
                                                        - originalValues$signal_mag
                                                        [lastIndex-1]) * Fs/2
                                    }
                                    beforeSlope <- (originalValues$signal_mag
                                                    [beforeIndex+1]
                                                    - originalValues$signal_mag
                                                    [beforeIndex-1]) * Fs/2
                                    if (abs(lastSlope) < (abs(beforeSlope)/2)) {
                                          if (length(index.falsePos) < index) {
                                                index.falsePos[[index]] <<- list()
                                          }
                                          index.falsePos[[index]][[indexIn]] <<- lastIndex
                                          indexIn <- indexIn + 1
                                          if (is.null(num.falsePosAUX)) {
                                                num.falsePosAUX <- 0
                                          }
                                          num.falsePosAUX <- num.falsePosAUX + 1
                                          noise.peaksAUX <- c(noise.peaksAUX,PEAKI)
                                          NPKI <- PKI(noise.peaksAUX)
                                          THR(SPKI, NPKI)
                                          next
                                    }
                              } else {
                                    if (length(index.falsePos) < index) {
                                          index.falsePos[[index]] <<- list()
                                    }
                                    index.falsePos[[index]][[indexIn]] <<- lastIndex <-
                                          lastIndex.originalSpeak
                                    indexIn <- indexIn + 1
                                    if (is.null(num.falsePosAUX)) {
                                          num.falsePosAUX <- 0
                                    }
                                    num.falsePosAUX <- num.falsePosAUX + 1
                                    noise.peaksAUX <- c(noise.peaksAUX,PEAKI)
                                    NPKI <- PKI(noise.peaksAUX)
                                    THR(SPKI, NPKI)
                                    next
                              }
                        }
                        #As condições abaixo tratam de testar a existência de falsos 
                        #---negativos, ou seja, se entre o último pico R classificado e o 
                        #---suposto atual existe outro pico R não detectado. 
                        lastIndex.Speak <- index.Speaks[length(index.Speaks)]
                        if (lastRR.originalInterval > 1.66*mean(RR.originalIntervalsAUX)){
                              peakValuesAUX <- (peakValues[(lastIndex.Speak+1)
                                                           :(index.RpeakAUX-1)])
                              peakValuesAUX2 <- (peakValuesAUX[peakValuesAUX < THR1
                                                               & peakValuesAUX > THR2])
                              new.Rpeak <- max(peakValuesAUX2, na.rm = TRUE)
                              if (!is.infinite(new.Rpeak)) {
                                    if (is.null(num.falseNegAUX)) {
                                          num.falseNegAUX <- 0
                                    }
                                    num.falseNegAUX <- num.falseNegAUX + 1
                                    indexRm.Npeak1 <- ((1:length(peakValuesAUX
                                                                [!is.na(peakValuesAUX)]))
                                                       [peakValuesAUX
                                                       [!is.na(peakValuesAUX)]==new.Rpeak]
                                                       )
                                    indexRm.Npeak2 <- ((1:length(peakValuesAUX))
                                                       [peakValuesAUX==new.Rpeak
                                                       & !is.na(peakValuesAUX)])
                                    signal.peaksAUX <- c(signal.peaksAUX,
                                                         new.Rpeak,PEAKI)
                                    noise.peaksAUX <- c((noise.peaksAUX[1:(length(
                                          noise.peaksAUX) - length(peakValuesAUX
                                                                   [!is.na(peakValuesAUX)]
                                                                   ))]),
                                          (noise.peaksAUX[(length(noise.peaksAUX)
                                                           - length(peakValuesAUX
                                                                    [!is.na(peakValuesAUX)
                                                                    ])+1):length(
                                                                          noise.peaksAUX)]
                                           [-indexRm.Npeak1]))
                                    index.Speaks <- c(index.Speaks,
                                                      lastIndex.Speak + indexRm.Npeak2,
                                                      index.RpeakAUX)
                              } else {
                                    signal.peaksAUX <- c(signal.peaksAUX, PEAKI)
                                    index.Speaks <- c(index.Speaks, index.RpeakAUX)
                              }
                        } else {
                              signal.peaksAUX <- c(signal.peaksAUX, PEAKI)
                              index.Speaks <- c(index.Speaks, index.RpeakAUX)
                        }
                        index.originalSpeaks <- index.originalALLpeaks[index.Speaks]
                        RR.originalIntervalsAUX <- diff(index.originalSpeaks)
                        SPKI <- PKI(signal.peaksAUX)
                  } else {
                        noise.peaksAUX <- c(noise.peaksAUX,PEAKI)
                        NPKI <- PKI(noise.peaksAUX)
                  }
                  THR(SPKI, NPKI)
            }
      }
      #-----------------------------------------------------------------------------------
      #No último bloco, os vetores gerados pelo processamento são armazenados nas listas 
      #---"RR.originalIntervals", "noise.peaks", "signal.peaks", "index.Rpeaks",
      #---"num.falsePos", "num.falseNeg" e "index.falsePos".
      if (!is.null(num.falsePosAUX)) {
            num.falsePos[[index]] <<- num.falsePosAUX
      }
      if (!is.null(num.falseNegAUX)) {
            num.falseNeg[[index]] <<- num.falseNegAUX
      }
      index.Rpeak[[index]] <<- index.originalSpeaks
      noise.peaks[[index]] <<- noise.peaksAUX
      signal.peaks[[index]] <<- signal.peaksAUX
      RR.originalIntervals[[index]] <<- RR.originalIntervalsAUX
      index <<- index + 1
}
```

Em seguida, os códigos que executam as funções anteriormente apresentadas.

```{r graph6}
initializingVariables()

mapply(classifying.peaks, dt.signal, peakValues, peakIndex, initial.THR)
```