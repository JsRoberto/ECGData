---
title: "Algoritmo de Pan & Tompkins para detecção de complexos QRS"
author: "José Roberto Sobrinho Lima e Luana Gonçalves"
date: "8 de outubro de 2016"
output: pdf_document
---
***
#Relatório  
***

##1. Introdução e Metodologia  

```{r setoptions}
knitr::opts_chunk$set(autodep = TRUE, cache = TRUE, warning = FALSE, results = "hide")
```
Doenças cardíacas estão entre as principais causas de mortalidade no mundo. Por esse motivo, há constante preocupação em melhorar o poder diagnóstico de equipamentos que monitoram a condição cardíaca. Uma grande variedade de dispositivos analisa a atividade cardíaca, produzindo informações que facilmente podem ser digitalizadas e processadas por computador. A medida que o poder computacional dessas máquinas cresce, os diagnósticos resultantes apresentam acurácia e precisão maiores.  

Em processamento de eletrocardiogramas (ECG), uma base importante para fundamentar posteriores análises dos dados é a acurácia na detecção de batimentos cardíacos. Nesse sentido, como a energia dos batimentos está localizada nos complexos QRS[nota 1], acurácia na detecção desses complexos é essencial para a análise de ECG.  

Devido à variação ao longo do tempo e aos diferentes tipos de ruído que podem contaminar o sinal ECG, a detecção do complexo QRS é uma tarefa difícil.  

Os algoritmos de detecção dos complexos QRS apresentam duas fases distintas: (1) o estágio de pré-processamento, que consiste em aplicar técnicas de filtragem linear e não linear ou “_smoothing_” – o objetivo é atenuar as ondas P e T, bem como os ruídos contaminantes; e (2) o estágio de decisão, que apresenta como tarefas mais importantes a determinação de “_thresholds_” para classificação e, em alguns casos, a discriminação de ondas T e a redução de falsos positivos.  

O algoritmo de detecção do complexo QRS a ser estudado e aplicado será o algoritmo de _Pan-Thompkins_, cujas etapas de processamento serão abordadas mais adiante. A discussão inclui a análise em pormenor do um código fonte desenvolvido neste trabalho e que utilizou parâmetros previamente estabelecidos em literatura sobre o tema [ref. ÁLVAREZ].  

O algoritmo de _Pan-Thopmpkins_ será aplicado sobre uma base de dados pública, obtida gratuitamente do bando de dados do _Physionet_[nota 2]. Mais especificamente, os dados que utilizaremos foram coletados e armazenados pelo _MIT_ e pelo _Boston’s Beth Israel Hospital_ (_MIT-BIH Arrhythmia Database_) segundo metodologia amplamente submetida a discussões e críticas – **ainda hoje carregando bastante credibilidade e relevância acadêmica**. Além, disso essa base de dados é focada em sinais com as mais diversas morfologias de complexos QRS[nota 3],  o que permite investigar a performance dos algoritmos de detecção desses complexos – daí, portanto, seu extensivo uso para validação desses algoritmos.  

O _MIT-BIH Arrhythmia Database_ contém 48 horas e meia de gravações coletadas utilizando-se dois canais de entrada. Todavia, o código fonte que desenvolvemos processará somente um desses canais: se um desses canais registrar sinais de alta qualidade, normalmente isso implica que o segundo canal registrará sinais de baixa amplitude e de baixa relação sinal-ruído[nota 4] (obs.: talvez mais alguma informação sobre o MIT-BIH).  

Os softwares utilizados serão:   
(1) _MatLab_, da _Mathworks_ – utilizar-se-á o WFDB Toolbox[nota 5], 
(2) _RStudio_, linguagem de programação R – ...para realizar o processamento dos sinais de ECG do MIT-BIH é a linguagem de programação R. Seus principais atrativos são seus ferramentais voltados para computação estatística e modelagem gráfica. Além disso, o software é _open source_ e apresenta estrutura multiplataforma.  

O algoritmo de Pan-Thompkins é baseado em filtros digitais, possuindo filtros passa-baixa e passa-alta em cascata e com frequências de cortes diferentes resultando em um sinal filtrado passa-banda.

***
##2. O código fonte  

O código fonte desenvolvido neste trabalho pode ser dividido em três momentos.  

###2.1 Fase de estabelecimento  

Esta etapa consiste em (1) estabelecer as bibliotecas a serem utilizadas dentro do código, entre as quais temos os pacotes gráficos _ggplot2_, _lattice_ e _gridExtra_, além do pacote _signal_, com funções de filtros digitais diretamente importadas do MatLab e Octave[ref. signal CRAN]; (2) baixar e salvar no diretório de trabalho os dois arquivos necessários ao processamento – *mtidb_signals.csv* e *fs.csv*; e (3) criar a principal função de plotagem gráfica _dataECGplot()_, que mostrará os resultados das principais etapas do processamento dos sinais.  

```{r}
#Localizar a biblioteca e definir os pacotes não padrões a serem utilizados.
.libPaths("C:/Users/JoséRoberto/AppData/Roaming/SPB_16.6/R/win-library/3.2")
library(signal)
library(ggplot2)
library(lattice)
library(gridExtra)

#Baixar os arquivos "mitdb_ecgSignals.csv" e "fs.csv" - caso ainda não tenham sido.
Url <- c("https://raw.githubusercontent.com/JsRoberto/ECGData/master/mitdb_ecgSignals.csv",
         "https://raw.githubusercontent.com/JsRoberto/ECGData/master/fs.csv")
Local <- c("mitdb_ecgSignals.csv","fs.csv")

download <- function(Local, Url) {
      if (!file.exists(Local)) {
            download.file(Url, Local)
      }
}

mapply(download, Local, Url)

#Salvar em formatos adequados as variáveis que representam os sinais.
Ecg.signals <- read.csv("mitdb_ecgSignals.csv", stringsAsFactors = FALSE)
Ecg.signals <- Ecg.signals[-((6*21601+1):dim(Ecg.signals)[1]),]
Ecg.signalSplit <- split(Ecg.signals, Ecg.signals$signal_case)
fs <- read.csv("fs.csv")
fs <- as.numeric(fs)
```
  
```{r results = "markup"}
#São obtidos a média "Mean1" e o desvio padrão "Std1" dos sinais não filtrados.
Mean1 <- sapply(Ecg.signalSplit, function(x) mean(x$signal_mag, na.rm = TRUE))
Std1 <- sapply(Ecg.signalSplit, function(x) sd(x$signal_mag, na.rm = TRUE))
Mean1
Std1
```
  
```{r}
#A função "filter_ecgSignals()" pretende aplicar sobre a lista de sinais "data_ecg" o 
#---filtro definido por uma função de transferência com numerador "H_Num" e denominador
#---"H_Den". Além disso, o sinal filtrado resultante "x_norm" está normalizado.
filter_ecgSignals <- function(data_ecgSplit, H_Num, H_Den) {
      x <- lapply(data_ecgSplit, function(x) x$signal_mag - mean(x$signal_mag))
      x <- sapply(x, filter, filt = H_Num, a = H_Den)
      x <- as.data.frame(x)
      x_norm <- sapply(x, function(x) {
            x <- x/max(abs(x))
      })
      x_norm <<- as.data.frame(x_norm)
}

filter_ecgSignals(Ecg.signalSplit, 1, 1)

#A função "update.filtSignal()" pretende atualizar a lista de sinais "Ecg.signalSplit"
#---pela lista de valores filtrados e normalizados "x_norm".
update.filtSignal <- function(Ecg.signalSplit, x_norm) {
      for (i in 1:length(Ecg.signalSplit)) {
            Ecg.signalSplit[[i]]$signal_mag <<- x_norm[[i]]
      }
}

update.filtSignal(Ecg.signalSplit, x_norm)
```
  
```{r results = "markup"}
#São obtidos a média "Mean2" e o desvio padrão "Std2" dos sinais normalizados.
Mean2 <- sapply(Ecg.signalSplit, function(x) mean(x$signal_mag, na.rm = TRUE))
Std2 <- sapply(Ecg.signalSplit, function(x) sd(x$signal_mag, na.rm = TRUE))
Mean2
Std2
```
  
```{r graph1}
#A função "dataECGplot()" é a principal função de plotagem do código, responsável por 
#---mostrar a evolução do sinal em cada etapa de processamento.
#---Seus argumentos são:
#---(1) "Ecg.signalSplit" - define a lista de sinais a serem plotados;
#---(2) "interval_seg" - define o intervalo de tempo em que o plote está delimitado;
#---(3) "Fs" - define a frequência de amostragem dos sinais.
dataECGplot <- function(Ecg.signalSplit, interval_seg = 0:60, Fs = fs) {
      Ecg.signalsAUX <- data.frame()
      signal_mag <- vector()
      interval <- 1+((Fs*min(interval_seg)):(Fs*max(interval_seg)))
      for (i in 1:length(Ecg.signalSplit)) {
            signal_mag <- c(signal_mag,
                            Ecg.signalSplit[[i]]$signal_mag[interval])
            Ecg.signalSplit[[i]] <- Ecg.signalSplit[[i]][interval,]
            Ecg.signalsAUX <- rbind(Ecg.signalsAUX,Ecg.signalSplit[[i]])
      }
      Ecg.signalsAUX$signal_mag <- signal_mag
      
      panel.smoother <- function(x, y) {
            panel.grid(h=-1, v=-1)
            panel.xyplot(x, y, type = "l", lwd = 1)
            panel.abline(h=mean(y), lwd=1, lty=2, col="navy")
      }
      
      xyplot(signal_mag ~ t | signal_case, data = Ecg.signalsAUX,
             layout=c(3,2),
             panel=panel.smoother,
             main="Ecg Signals", xlab="time (s)",ylab="Volts")
}

dataECGplot(Ecg.signalSplit, 25:35)
```
  
###2.2 Algoritmo de _Pan & Thompkins_  

O método que Pan & Tompkins desenvolveram para realizar a detecção dos complexos QRS de sinais de ECG é capaz de realizar a tarefa em tempo. Para tanto, o algoritmo é baseado na inclinação, amplitude e tamanho do sinal - não se limita, pois, somente à inclinação da onda R do sinal.  
Esse algoritmo é divido em dois estágios, pré-processamento e decisão.  
O estágio de pré-processamento consiste em preparar os sinais para a posterior detecção, eliminando os ruidos dos sinais mediante filtros e realçando a inclinação QRS para tornar mais eficiente sua detecção.  
O estágio de decisão consiste em (1) detectar os picos dos sinais, (2) obter e atualizar constantee automaticamente parâmetros que classifiquem esses picos detectados, ou como oriundos de ruidos, ou como próprios do sinal. As informações obtidas durante essa etapa são utilizadas principalmente para eliminar falsos positivos e reintegrar falsos negativos.

####2.2.1 Fase de pré-processamento  

Nessa fase, o sinal passa por um bloco de filtros para reduzir ruídos e influência das ondas T. Esse bloco de filtros é composto por um passa-baixa e um passa-alta em cascata, com o intuito de construir um passa-banda entre 9-20 Hz com 3 dB de atenuação [ref. RANGAYYAN]. O passa-baixa é usado para remover ruídos de altas frequências e o passa-alta é usado para atenuar as ondas P e T e o "baseline drift". O filtro digital passa-banda aumenta a relação sinal-ruido (SNR).  

```{r graph2, fig.height = 4, fig.width = 4, fig.align = "center"}
#Bloco 1 - Filtro passa-baixa.
N_lp <- c(1,rep(0,5),-2,rep(0,5),1)
D_lp <- 32*c(1,-2,1)

H_lpz <- freqz(N_lp, D_lp, Fs = fs) #Fs = 360 Hz admite Fc = 20 Hz.

filter_ecgSignals(Ecg.signalSplit, N_lp, D_lp)

update.filtSignal(Ecg.signalSplit, x_norm)

#A função "fz_plot()" pretende gerar gráficos das respostas frequenciais dos filtros: 
#---magnitude (dB e linear) e fase em função da frequência normalizada.
#---Seus argumentos são: 
#---(1) "filter_freqz" - define o filtro propriamente dito, mediante a classe "freqz";
#---(2) "filter_type" - define se o filtro é passa-baixa "lp" ou passa-alta "hp";
#---(3) "Fs" - define a frequência de amostragem do filtro.
fz_plot <- function(filter_freqz, filter_type, Fs = fs){
      df <- data.frame(w = rep(0,length(filter_freqz$f)),
                       mag = rep(0,length(filter_freqz$h)),
                       mag_dB = rep(0,length(filter_freqz$h)),
                       phase_degrees = rep(0,length(filter_freqz$h)))
      df$w <- filter_freqz$f/(Fs/2)
      df$mag <- abs(filter_freqz$h)
      df$mag_dB <- 20*log10(abs(filter_freqz$h))
      df$phase_degrees <- (180/pi)*Arg(filter_freqz$h)
      
      vec_aux <- df$mag_dB
      vec_aux <- vec_aux[-1]
      vec_aux <- vec_aux + 3
      vec_aux <- vec_aux^2
      wc_sample <- numeric()
      for (i in 1:(dim(df)[1]/2)) {
            if (df$mag_dB[-1][i] == df$mag_dB[-1][vec_aux == min(vec_aux, na.rm = TRUE)]) {
                  wc_sample <- i + 1
            }
      }
      
      interval <- wc_sample:512 #default case: low pass filter "lp"
      type <- "Low"
      if (filter_type == "hp"){
            interval <- 1:wc_sample
            type <- "High"
      }
      
      p1 <- ggplot(data=df, aes(x=w, y=mag)) +
            geom_line(color = "navy", size = 1) +
            geom_line(data = df[interval,], color = "red", size = 1.3) +
            labs(x="",y="Magnitude")
      p2 <- ggplot(data=df, aes(x=w, y=mag_dB)) +
            geom_line(color = "navy", size = 1) +
            geom_line(data = df[interval,], color = "red", size = 1.3) +
            labs(x="",y="Magnitude (dB)")
      p3 <- ggplot(data=df, aes(x=w, y=phase_degrees)) +
            geom_line(color = "navy", size = 1) +
            labs(x="",y="Phase (degrees)")
      
      labs_title <- labs(title=paste(type,"Pass Filter - Frequency Response"))
      labs_x <- labs(x=expression(paste("Normalized Frequency (x ",pi," rad/sample)")))
      
      grid.arrange(p1 + labs_title, p2, p3 + labs_x, nrow=3)
}

fz_plot(H_lpz, "lp")
```
  
```{r graph3, fig.height = 4, fig.width = 4, fig.align = "center"}
#Bloco 2 - Filtro passa-alta.
N_hp <- c(-1,rep(0,15),32,-32,rep(0,14),1)
D_hp <- 32*c(1,-1)

H_hpz <- freqz(N_hp, D_hp, Fs = fs) #Fs = 360 Hz admite Fc = 9 Hz

filter_ecgSignals(Ecg.signalSplit, N_hp, D_hp)

update.filtSignal(Ecg.signalSplit, x_norm)

fz_plot(H_hpz, "hp")
```

Em seguida, um operador derivativo é aplicado sobre o sinal filtrado anteriormente, fornecendo informações complexas sobre as inclinações. A partir daí, eleva-se ao quadrado ponto a ponto, o que intensifica a inclinação do sinal derivado e ajuda a reduzir falsos positivos causados por ondas T maiores que as usuais.  

```{r graph4}
#Bloco 3 - Operador derivativo.
N_do <- c(2,1,0,-1,-2)
D_do <- 8

filter_ecgSignals(Ecg.signalSplit, N_do, D_do)

update.filtSignal(Ecg.signalSplit, x_norm)

dt.signal <- Ecg.signalSplit

dataECGplot(dt.signal, 25:35)

#Bloco 4 - Operador que eleva os valores dos sinais ao quadrado.
x_norm <- lapply(x_norm, function(x) x - mean(x))
x_norm <- sapply(x_norm, function(x) x^2)
x_norm <- as.data.frame(x_norm)

update.filtSignal(Ecg.signalSplit, x_norm)
```  

Finalmente, uma janela de integração móvel é aplicada, o que agrega informações sobre inclinação e largura do sinal. O tamanho da janela de integração é muito importante, uma vez que deve sempre conter o complexo QRS. As dificuldades são que (1) o complexo QRS pode apresentar diferentes extensões e (2) o tamanho da janela não deve excedê-lo, porquanto não deve se misturar a outras formas de onda, como a onda T. A janela utilizada apresenteu os melhores resultados, segundo ÁLVAREZ, com uma janela de 150 ms - isso corresponde a `r 0.15*fs` amostras. Além disso, cabe ressaltar que todas as etapas de processamento, seja a etapa dos filtros que constituem o passa-banda, as operações derivativas ou a janela de integração móvel, todas elas causam _delays_ que devem ser considerados quando comparados os sinais resultantes de cada etapa.  

```{r graph5}
#Bloco 5 - Janela de integração móvel
N_if <- rep(1,54)
D_if <- 54

filter_ecgSignals(Ecg.signalSplit, N_if, D_if)

update.filtSignal(Ecg.signalSplit, x_norm)

mwi.signal <- Ecg.signalSplit

dataECGplot(mwi.signal, 25:35)
```

####2.2.2 Fase de decisão  

Uma vez que o sinal é pré-processado, ele está preparado para a detecção dos complexos QRS. Como dito anteriormente, essa fase tem o objetivo de detectar picos e classificá-los. Esse procedimento será aplicado a dois conjuntos de sinais: o primeiro é o conjunto de sinais filtrados pelo bloco derivativo (doravante _dt.signal_) e o segundo é o cojunto de sinais filtrado pela janela de integração (doravante _mwi.signal_).  

O código que realiza a detecção de picos se apresenta abaixo.  

```{r}
#A função "peakDetection()" apresenta como argumentos (a) "updated.dataSplit", uma lista
#---de sinais atualizada pela função "update.filtSignal()", (b) "samples", a quantidade
#---de amostras que terá cada segmento de um sinal, (c) "Fs", a frequência de amostragem
#---dos sinais.
#---O objetivo desta função é obter duas listas: 
#---(1) "peakValues", que armazena os vetores de picos de cada sinal;
#---(2) "peakIndex", que armazena os vetores de índices de cada pico.
peakDetection <- function(updated.dataSplit, samples, Fs = fs) {
      peak.values <- data.frame()
      peak.index <- list()
      k <- 0:(Fs*60/samples)*samples
      for (i in 1:(Fs*60/samples)) {
            if (i == Fs*60/samples) {
                  k[i+1] <- k[i+1] + 1
            }
            peak.intervalAUX <- lapply(updated.dataSplit,
                                       function(x) x$signal_mag[(k[i]+1):k[i+1]])
            peak.valuesAUX <- lapply(peak.intervalAUX,max)
            peak.indexAUX <- mapply(function(peak,intmag) (k[i]:k[1+i])[intmag==peak],
                                    peak.valuesAUX,peak.intervalAUX)
            maximum <- 0
            for (l in 1:length(updated.dataSplit)){
                  if (length(peak.indexAUX[[l]]) > maximum) {
                        maximum <- length(peak.indexAUX[[l]])
                  }
            }
            if (maximum > 1) {
                  for (aux in 1:length(updated.dataSplit)) {
                        peak.valuesAUX[[aux]] <- c(rep(peak.valuesAUX[[aux]],length(peak.indexAUX[[aux]])),
                                                   rep(NA, maximum - length(peak.indexAUX[[aux]])))
                        peak.indexAUX[[aux]] <- c(peak.indexAUX[[aux]],
                                                  rep(NA,maximum - length(peak.indexAUX[[aux]])))
                  }
            }
            peak.valuesAUX <- as.data.frame(peak.valuesAUX)
            peak.values <- rbind(peak.values,peak.valuesAUX)
            for (j in 1:length(updated.dataSplit)) {
                  if (length(peak.index) < j) {
                        peak.index[[j]] <- list()
                  }
                  peak.index[[j]][[i]] <- peak.indexAUX[[j]]
            }
      }
      peakValues <<- as.data.frame(peak.values,
                                   row.names = 1:dim(peak.values)[1])
      peakIndex <<- peak.index
}
```

A natureza dos parâmetros de classificação do algoritmo de Pan & Tompkins é iterativa, ou seja, a cada novo pico classificado, os parâmetros são atualizados para classificar os seguintes. Todavia, cabe a dúvida: como classificar os primeiros picos?  

A solução foi obter um parâmetro classificatório inicial e fixo, a fim de determinar os tipos, se de ruido ou de sinal, da menor quantidade de picos necessária para, a partir daí, utilizar o algoritmo do parâmetro de classificação adaptativo.  

Assim, o parâmetro inicial e fixo foi obtido calculando-se 35 % do valor da mediana do vetor de picos do sinal, quando este foi segmentado em intervalos de 3 segundos ou `r 3*fs` amostras. Esse valor se justifica devido ao seguinte raciocínio: a frequência cardíaca minima do ser humano é de 25 batimentos/min, ou seja, um batimento a cada 2,4 segundos; então, a cada 3 segundos, com certeza há pelo menos um pico R em um sinal de ECG.  

A partir daí, um novo vetor de picos foi gerado a partir de segmentação em intervalos de 80 amostras: intervalos menores detectariam muitos picos, enquanto intervalos maiores poderiam não detectar alguns ou muitos deles. Será precisamente este novo vetor que deverá ser classificado, primeiramente usando o parâmetro inicial fixo e posteriormente o parâmetro adaptativo.

```{r}
#Aplicação sobre a lista "dt.signal".
#A primeira aplicação da função "peakDetection()" é usada pra obter os parâmetros 
#---iniciais de classificação "initial.THR".
peakDetection(dt.signal, fs*3, fs)
initial.THR <- 0.35*apply(peakValues, 2, median, na.rm = TRUE)

#A segunda aplicação da função "peakDetection()" é usada pra obter os valores dos picos
#---que serão usados para classificação.
peakDetection(dt.signal, 80, fs)
```

O algoritmo para obtenção dos parâmetros adaptativos consiste nas seguintes variáveis de iteração:  

SPKI = 0.125 × PEAKI + 0.875 × SPKI **(1)**  
NPKI = 0.125 × PEAKI + 0.875 × NPKI **(2)**  
THR1 = NPKI + 0.25 × (SPKI - NPKI) **(3)**  
THR2 = 0.5 × THR1 **(4)**  

Onde PEAKI é o pico corrente, aplicado sobre a função **(1)** se for um pico de sinal ou sobre a função **(2)** se for um pico de ruido; e as variáveis THR1 e THR2 de **(3)** e **(4)**, respectivamente, são os parâmetros de classificação que se adaptam a cada novo pico classificado.

O código abaixo auxilia na obtenção dessas variáveis.  

```{r}
#A função "PKI()" tem o objetivo de gerar os parâmetros de NPKI e SPKI utilizados por Pan 
#---& Tompkins. Se o "vector.peaks" utilizado argumento for "noise.peaks", NPKI é obtido;
#---se for "signal.peaks", então SPKI é obtido. 
PKI <- function(vector.peaks) {
      if (length(vector.peaks)==1) {
            PEAKI <- vector.peaks[1]
      } else {
            PEAKI <- 0.125*vector.peaks[length(vector.peaks)] + 0.875*PKI(vector.peaks[-length(vector.peaks)])
      }
      PEAKI
}

#A função "THR()" utiliza os parâmetros NPKI e SPKI, obtidos com a função "PKI()", para
#---gerar os parâmetros de classificação dos picos dos sinais.
THR <- function(SPKI, NPKI) {
      THR1 <<- NPKI + 0.25*(SPKI - NPKI)
      THR2 <<- 0.5*THR1
}
```

O parâmetro THR1 é o principal fator de classificação: se o valor do pico corrente for maior que THR1, ele é classificado como pico de sinal; caso contrário, como pico de ruido. Contudo, existem alguns picos de sinal não detectados, ou devido à irregularidade do sinal, ou devido a formas de ondas com mudanças abruptas de amplitude ou frequência. Ou seja, o método inclui algoritmo para eliminar _**falsos negativos**_.  

Algoritmo para detecção e reintegração de _**falsos negativos**_ → se o intervalo entre os dois últimos picos R detectados for maior que 166 % da média das distâncias entre todos os demais pares de picos R adjacentes, então uma nova condição é testada para verificar a existência de picos R não detectados: ser simultaneamente menor que THR1 e maior que THR2.  
Um novo problema surge quando a distância entre picos R é pequenos demais: a grande possibilidade de ser uma forma de onde T 


 
***
Os parâmetros de classificação variam de acordo com o ruído que é detectado pelo algoritmo, atualizando automaticamente suas diretrizes a cada nova classificação feita, demonstrando que o algoritmo possui alta adaptabilidade ao se ajustar às características específicas do sinal.  

**Nessa fase, dois conjuntos de parâmetros de classificação são aplicados: o primeiro se aplica ao sinal filtrado pelo bloco derivativo (doravante _dt.signal_) e o segundo, ao sinal filtrado pela janela de integração (doravante _mwi.signal_). Após essas aplicações, deve-se comparar os dois conjuntos de sinais resultantes, o que permitirá um aumento na confiabilidade da detecção se comparado à detecção feita com apenas um deles, _dt.signal_ ou _mwi.signal_. Cabe ressaltar, contudo, que não procedemos no nosso trabalho com está última etapa do processamento, limitando-nos a utilizar os resultados que o algoritmo de classificação obteve quando aplicado sobre _dt.signal_.**